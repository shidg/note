# 设置当前上下文中所有后续 kubectl 命令使用的命名空间
kubectl config set-context --current --namespace=<insert-namespace-name-here>


# 根据label标签过滤查询结果
kubectl get pods -l environment=production,tier=frontend
kubectl get pods -l 'environment in (production),tier in (frontend)'
kubectl get pods -l 'environment in (production, qa)'
kubectl get pods -l 'environment,environment notin (frontend)'

# field-selector
kubectl get pods --field-selector status.phase=Running
kubectl get pods --field-selector=status.phase!=Running,spec.restartPolicy=Always

# 设置节点为不可调度
kubectl cordon nodename
# 去除不可调度
kubectl uncordon nodename

# 驱逐节点上的pod
kubectl drain nodename --delete-local-data --ignore-daemonsets --force

# --delete-local-data 即使pod使用了emptyDir也删除
# --ignore-daemonsets 忽略deamonset控制器的pod，如果不忽略，deamonset控制器控制的pod被删除后可能马上又在此节点上启动起来,会成为死循环；
# --force 不加force参数只会删除该NODE上由ReplicationController, ReplicaSet, DaemonSet,StatefulSet or
# Job创建的Pod，加了后还会删除'裸奔的pod'(没有绑定到任何replication controller)


# 增加node节点
# master上
# kubeadm token create --print-join-command

# node上
# kubeadm reset
#   kubeadm join 172.31.182.156:8443  --token ortvag.ra0654faci8y8903 \
    --discovery-token-ca-cert-hash sha256:04755ff1aa88e7db283c85589bee31fabb7d32186612778e53a536a297fc9010

# 增加master节点
# 原master上
# kubeadm token create --print-join-command
# kubeadm init phase upload-certs --upload-certs

# 新master上
# kubeadm reset
#   kubeadm join 172.31.182.156:8443  --token ortvag.ra0654faci8y8903 \
    --discovery-token-ca-cert-hash sha256:04755ff1aa88e7db283c85589bee31fabb7d32186612778e53a536a297fc9010 \
    --experimental-control-plane --certificate-key f8d1c027c01baef6985ddf24266641b7c64f9fd922b15a32fce40b6b4b21e47d

######## 如果是集群中原有的某台master因故退出了集群，想要重新加入到集群中并且仍作为master
# 需要在集群中首先清理掉该master在集群中的信息（集群的etcd和configmap中仍记录着该master的信息）
# 清理方法如下：
# kubectl  exec -it -n kube-system etcd-k8s-masterxx --sh
$ export ETCDCTL_API=3
$ alias etcdctl='etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key'
$ etcdctl member list
## 删除要删除的etcd 集群成员
$ etcdctl member remove 63bfe05c4646fb08
$ exit

# 清理cm中的相关信息
# kubectl -n kube-system get cm kubeadm-config -o yaml > tmp-kubeadm-config.yaml
# manually edit tmp-kubeadm-config.yaml to remove the old server
# kubectl -n kube-system apply -f tmp-kubeadm-config.yaml
# 然后再执行加入集群的命令即可
# kubeadm reset
#   kubeadm join 172.31.182.156:8443  --token ortvag.ra0654faci8y8903 \
    --discovery-token-ca-cert-hash sha256:04755ff1aa88e7db283c85589bee31fabb7d32186612778e53a536a297fc9010 \
    --experimental-control-plane --certificate-key f8d1c027c01baef6985ddf24266641b7c64f9fd922b15a32fce40b6b4b21e47d


# 回滚
kubectl rollout history deployment ${deployment_name}
kubectl rollout undo deployment ${deployment_name} --to-revision=1


# 如何查看可用的镜像版本
# ${docker_img}为镜像名
curl https://registry.hub.docker.com/v1/repositories/${docker_img}/tags | python3 -m json.tool | more



# 强制删除namespace 
# kubectl get ns -o json > 1.json
# 将1.json中的spec中的内容清空
# kubectl proxy
curl -k -H "Content-Type: application/json" -X PUT --data-binary @1.json http://127.0.0.1:8001/api/v1/namespaces/<name>/finalize


## docker设置socks代理
mkdir -p /etc/systemd/system/docker.service.d && touch /etc/systemd/system/docker.service.d/http-proxy.conf
cat > /etc/systemd/system/docker.service.d/http-proxy.conf << EOF
[Service]
Environment="HTTP_PROXY=socks5://127.0.0.1:1080" "HTTPS_PROXY=socks5://127.0.0.1:1080" "NO_PROXY=localhost,127.0.0.1,"
EOF

systemctl daemon-reload && systemctl restart docker

#验证是否配置成功
systemctl show --property=Environment docker

#另外如果需要使用http代理，只需要将socks5替换成http。
