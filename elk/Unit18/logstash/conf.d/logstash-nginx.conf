#input {
#    beats {
#        port => 5044
#    }
#}

input {
  kafka {
    #topics => "nginx-access-log"
    topics_pattern => "nginx-access-log-.*"
    bootstrap_servers => "10.203.43.101:9092,10.203.43.102:9092,10.203.43.103:9092"
    auto_offset_reset => "earliest" 
    group_id => "nginx-log"
    client_id => 1
    codec => json {
      charset => "UTF-8"
    }
  }
}


filter {
  grok {
    #match => { "message" => "%{IPORHOST:remote_ip} - %{DATA:user_name} \[%{HTTPDATE:local_time}\] \"%{WORD:method} %{DATA:url} HTTP/%{NUMBER:http_version}\" %{NUMBER:response_code} %{NUMBER:body_sent:bytes} \"%{DATA:referrer}\" \"%{DATA:user_agent}\" \"%{NUMBER:request_time}\"  \"%{DATA:http_x_forwarded_for}\" %{IPORHOST:http_host} " }
    patterns_dir => ["/etc/logstash/patterns"]
    match => { "message" => "%{NGINXACCESS}" }
    remove_field => "message"
  }

  date {
    match => ["local_time", "dd/MMM/yyyy:HH:mm:ss Z"]
    target => "@timestamp"
  }

  mutate {
    remove_field => "agent"
    remove_field => "ecs"
    remove_field => "log"
    remove_field => "host"
  }
}

output {
  elasticsearch {
    hosts => ["http://10.203.43.101:9200"]
    # 索引名称，不存在会自动创建
    index => "shidegang-kafka-%{+YYYY.MM.dd}"
  }
}
